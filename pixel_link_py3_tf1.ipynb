{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pixel_link_py3_tf1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxv2k/pixel_link_py3/blob/master/pixel_link_py3_tf1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhtCUDK2ULYH"
      },
      "source": [
        "# Setup env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkvKyBqFkTPC"
      },
      "source": [
        "## Init WanDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yRlIJSDckVfx",
        "outputId": "e2ebbfd4-61f6-4892-96da-09f77872e91f"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/f6/91c07f54c2162854f5028aaa13f576ca17a3bc0cf6da02c2ad5baddae128/wandb-0.10.33-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 12.7MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/75fad31fff378871c462745ce724b3701a6acad17028d79476ec2545e40f/sentry_sdk-1.3.0-py2.py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 36.7MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.8MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=ea16680d8e6ff558b3b4d81fe4ee31a61a924c037f1bb91ded1ed1d7d93aa8f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=03b927e4a2f776a142b16eec06f32d96a809a002f52c33045545c2d01e872d99\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: smmap, gitdb, GitPython, pathtools, docker-pycreds, configparser, shortuuid, sentry-sdk, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.33<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">radiant-universe-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/dxv2k/uncategorized\" target=\"_blank\">https://wandb.ai/dxv2k/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/dxv2k/uncategorized/runs/225mjs2z\" target=\"_blank\">https://wandb.ai/dxv2k/uncategorized/runs/225mjs2z</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210709_083732-225mjs2z</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fc852ed39d0>"
            ],
            "text/html": [
              "<h1>Run(225mjs2z)</h1><iframe src=\"https://wandb.ai/dxv2k/uncategorized/runs/225mjs2z\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41in5jmgLdtH"
      },
      "source": [
        "## Mount drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_THVYjxEIPYz",
        "outputId": "9bc43707-55dd-4f9c-f4b4-ec589399635c"
      },
      "source": [
        "# Mount Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QycXd7SLMclQ"
      },
      "source": [
        "# IC15 data dir\n",
        "IC15_PATH = \"/content/drive/MyDrive/ICDAR2015/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCIeiS48k2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e1b260-815e-485c-9b04-0997fe532c6a"
      },
      "source": [
        "# !git clone https://github.com/ZJULearning/pixel_link\n",
        "!git clone https://github.com/dxv2k/pixel_link_py3.git  \n",
        "# !cd pixel_link; rm -rf pylib; git clone https://github.com/dengdan/pylib.git\n",
        "PIXEL_LINK_ROOT = '/content/pixel_link_py3'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pixel_link_py3'...\n",
            "remote: Enumerating objects: 253, done.\u001b[K\n",
            "remote: Counting objects: 100% (253/253), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 253 (delta 69), reused 246 (delta 64), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (253/253), 6.65 MiB | 19.01 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dj8enbOLnPm"
      },
      "source": [
        "## Uninstall TF 2.5 & Install TF 1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVKx6gnMDOUD",
        "outputId": "cea5187d-56eb-4f43-d0fc-b2b51fdfb129"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow==1.13.1\n",
        "!pip install setproctitle \n",
        "# Install pip packages based on conda environment\n",
        "!grep \"==\" {PIXEL_LINK_ROOT}/pixel_link_env.txt | sed -E \"s/^.*- (.*)$/\\1/\" | xargs pip install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.5.0:\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6MB 88kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.34.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 33.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.6.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, keras-applications, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n",
            "Collecting setproctitle\n",
            "  Downloading https://files.pythonhosted.org/packages/97/5c/16a6e69febfbee3f1a1a8c4318d1f054ff4d3ef2a61b233937c316cba06d/setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Installing collected packages: setproctitle\n",
            "Successfully installed setproctitle-1.2.2\n",
            "Collecting backports.functools-lru-cache==1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/03/8e/2424c0e65c4a066e28f539364deee49b6451f8fcd4f718fefa50cc3dcf48/backports.functools_lru_cache-1.5-py2.py3-none-any.whl\n",
            "Collecting bottle==0.12.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/99/04dc59ced52a8261ee0f965a8968717a255ea84a36013e527944dbf3468c/bottle-0.12.13.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Collecting cython==0.28.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/9d/dea8c5181cdb77d32e20a44dd5346b0e4bac23c4858f2f66ad64bbcf4de8/Cython-0.28.2.tar.gz (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 24.3MB/s \n",
            "\u001b[?25hCollecting enum34==1.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Collecting kiwisolver==1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/7e/d6cae2f241ba474a2665f24b480bf4e247036d63939dda2bbc4d2ee5069d/kiwisolver-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.3MB/s \n",
            "\u001b[?25hCollecting matplotlib==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/1d/e6d9af0b5045597869537391f1036ab841c613c3f3e40f16bbc1d75450ee/matplotlib-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (12.6MB)\n",
            "\u001b[K     |████████████████████████████████| 12.6MB 229kB/s \n",
            "\u001b[?25hCollecting olefile==0.44\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/17/c15d41d5a8f8b98cc3df25eb00c5cee76193114c78e5674df6ef4ac92647/olefile-0.44.zip (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.1MB/s \n",
            "\u001b[?25hCollecting pillow==4.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/82/ec499c78bfe4ecaa91c2f3000040451d187ed0a816d58b8543e29c48827f/Pillow-4.3.0.tar.gz (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 239kB/s \n",
            "\u001b[?25hCollecting polygon2==2.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9e/fe761e03de28b51b445ddf01ddae87441b7e7040df7d830b86db8f945808/Polygon2-2.0.8.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSSsoHFQL4xi"
      },
      "source": [
        "## Export PYTHONPATH & LD_LIBRARY_PATH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhvFmI7S8uQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5a4bb7-693e-4ce4-a2e9-7964c99e4f0e"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] = os.environ['PYTHONPATH'] + \":\" + PIXEL_LINK_ROOT + \"/pylib/src\"\n",
        "# os.environ['LD_LIBRARY_PATH']= os.getcwd()\n",
        "\n",
        "!echo $LD_LIBRARY_PATH\n",
        "!echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib64-nvidia\n",
            "/env/python:/content/pixel_link_py3/pylib/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31jXsZulLvvl"
      },
      "source": [
        "## Download Pretrained Pixel Link VGG16 4s "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znsic8TV95KE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b4a811-77ee-4257-e0cd-697bf325eda8"
      },
      "source": [
        "# Download pretrained model\n",
        "!gdown --id 19mlX5W8OBalSjhf5oTTS6qEq2eAU8Tg9\n",
        "!unzip pixel_link_vgg_4s.zip\n",
        "MODEL_PATH = '/content/conv3_3'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19mlX5W8OBalSjhf5oTTS6qEq2eAU8Tg9\n",
            "To: /content/pixel_link_vgg_4s.zip\n",
            "229MB [00:04, 56.8MB/s]\n",
            "Archive:  pixel_link_vgg_4s.zip\n",
            "   creating: conv3_3/\n",
            "  inflating: conv3_3/checkpoint      \n",
            "  inflating: conv3_3/config.py       \n",
            "  inflating: conv3_3/model.ckpt-38055.data-00000-of-00001  \n",
            "  inflating: conv3_3/model.ckpt-38055.meta  \n",
            "  inflating: conv3_3/model.ckpt-38055.index  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm7WFCq2tm-Q"
      },
      "source": [
        "`from past.builtins import xrange`\n",
        "\n",
        "Add this in pretrained model, `config.py` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZESV7ZZB2ua"
      },
      "source": [
        "## Download image test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao-RY2smACNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d70cfb-4fce-4a2e-8445-54627a45a401"
      },
      "source": [
        "# Download test image\n",
        "PATH_ICDAR15 = '/content/'\n",
        "!mkdir {PATH_ICDAR15}/ch4_test_images; cd {PATH_ICDAR15}/ch4_test_images; \\\n",
        "    wget https://blog.mycar.vn/wp-content/uploads/2019/11/bien-bao-giao-thong.jpg;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-09 08:39:48--  https://blog.mycar.vn/wp-content/uploads/2019/11/bien-bao-giao-thong.jpg\n",
            "Resolving blog.mycar.vn (blog.mycar.vn)... 103.152.165.90\n",
            "Connecting to blog.mycar.vn (blog.mycar.vn)|103.152.165.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89390 (87K) [image/jpeg]\n",
            "Saving to: ‘bien-bao-giao-thong.jpg’\n",
            "\n",
            "bien-bao-giao-thong 100%[===================>]  87.29K   152KB/s    in 0.6s    \n",
            "\n",
            "2021-07-09 08:39:50 (152 KB/s) - ‘bien-bao-giao-thong.jpg’ saved [89390/89390]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtzqztIvWpNZ"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXeN4NjZURVT"
      },
      "source": [
        "## Single Image 4s Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfjTWVTV_zjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37248cbe-a1c5-4a89-fbdc-74682058d534"
      },
      "source": [
        "!chmod 777 {PIXEL_LINK_ROOT}/scripts/test.sh\n",
        "!cd {PIXEL_LINK_ROOT}; \\\n",
        "    ./scripts/test.sh 0 {MODEL_PATH}/model.ckpt-38055 {PATH_ICDAR15}/ch4_test_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++ set -e\n",
            "++ export CUDA_VISIBLE_DEVICES=0\n",
            "++ CUDA_VISIBLE_DEVICES=0\n",
            "++ python test_pixel_link.py --checkpoint_path=/content/conv3_3/model.ckpt-38055 --dataset_dir=/content//ch4_test_images --gpu_memory_fraction=-1\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running\n",
            "INFO:tensorflow:loading config.py from /content/conv3_3/config.py\n",
            "WARNING:tensorflow:From /content/pixel_link_py3/preprocessing/ssd_vgg_preprocessing.py:433: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From test_pixel_link.py:110: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "2021-07-09 08:45:22.521418: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-07-09 08:45:22.525309: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-07-09 08:45:22.525619: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d93f860ec0 executing computations on platform Host. Devices:\n",
            "2021-07-09 08:45:22.525658: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/conv3_3/model.ckpt-38055\n",
            "tcmalloc: large alloc 2516770816 bytes == 0x55d9683a6000 @  0x7fd9d0a161e7 0x7fd9bb6d59c5 0x7fd9bb819585 0x7fd9bb81bc94 0x7fd9bb827674 0x7fd9b5c1c29e 0x7fd9b5c1c62f 0x7fd9b5c86362 0x7fd9b5c83578 0x7fd9cf2f8a50 0x7fd9d07cb6db 0x7fd9cf90071f\n",
            "1/1: bien-bao-giao-thong\n",
            "result has been written to: /content/conv3_3/test/icdar2015_test/model.ckpt-38055/txt/res_bien-bao-giao-thong.txt\n",
            "cd /content/conv3_3/test/icdar2015_test/model.ckpt-38055;zip -j /content/conv3_3/test/icdar2015_test/model.ckpt-38055/model.ckpt-38055_det.zip /content/conv3_3/test/icdar2015_test/model.ckpt-38055/txt/*\n",
            "zip file created:  /content/conv3_3/test/icdar2015_test/model.ckpt-38055/model.ckpt-38055_det.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcJd1ADgQA0k"
      },
      "source": [
        "## Inference on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3_f1fCLrbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51cd439d-1c35-49f8-d0e5-7d9663312fbe"
      },
      "source": [
        "!cd {PIXEL_LINK_ROOT}; \\\n",
        "    ./scripts/test.sh 0 {MODEL_PATH}/model.ckpt-38055 {IC15_PATH}/ch4_test_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++ set -e\n",
            "++ export CUDA_VISIBLE_DEVICES=0\n",
            "++ CUDA_VISIBLE_DEVICES=0\n",
            "++ python test_pixel_link.py --checkpoint_path=/content/conv3_3/model.ckpt-38055 --dataset_dir=/content/drive/MyDrive/ICDAR2015//ch4_test_images --gpu_memory_fraction=-1\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running\n",
            "INFO:tensorflow:loading config.py from /content/conv3_3/config.py\n",
            "Traceback (most recent call last):\n",
            "  File \"test_pixel_link.py\", line 176, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"test_pixel_link.py\", line 171, in main\n",
            "    config_initialization()\n",
            "  File \"test_pixel_link.py\", line 76, in config_initialization\n",
            "    num_gpus = 1, \n",
            "  File \"/content/conv3_3/config.py\", line 153, in init_config\n",
            "    clone_scopes = ['clone_%d'%(idx) for idx in xrange(num_clones)]\n",
            "NameError: name 'xrange' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouFFpHnNMMFe"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmL37XDAtvQL"
      },
      "source": [
        "### Run bash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abh4EezIaH6m",
        "outputId": "84d43076-c699-43b6-f249-9c45b0bdd278"
      },
      "source": [
        "!cd {PIXEL_LINK_ROOT}/scripts; chmod 777 train.sh \n",
        "!cd {PIXEL_LINK_ROOT}; \\\n",
        "    ./scripts/train.sh 0 16 --checkpoint_path \"/content/conv3_3/model.ckpt-38055\"\n",
        "    # ./scripts/train.sh 0 8 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++ set -e\n",
            "++ export CUDA_VISIBLE_DEVICES=0\n",
            "++ CUDA_VISIBLE_DEVICES=0\n",
            "++ IMG_PER_GPU=16\n",
            "++ TRAIN_DIR=/content/pixel_link\n",
            "++ OLD_IFS=' \t\n",
            "'\n",
            "++ IFS=,\n",
            "++ gpus=($CUDA_VISIBLE_DEVICES)\n",
            "++ IFS=' \t\n",
            "'\n",
            "++ NUM_GPUS=1\n",
            "+++ expr 1 '*' 16\n",
            "++ BATCH_SIZE=16\n",
            "++ DATASET=icdar2015\n",
            "++ DATASET_DIR=/content/drive/MyDrive/icdar2015\n",
            "++ python train_pixel_link.py --train_dir=/content/pixel_link --num_gpus=1 --learning_rate=1e-3 --gpu_memory_fraction=-1 --train_image_width=512 --train_image_height=512 --batch_size=16 --dataset_dir=/content/drive/MyDrive/icdar2015 --dataset_name=icdar2015 --dataset_split_name=train --max_number_of_steps=100 --checkpoint_path= --using_moving_average=1\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running\n",
            "log file path:/content/pixel_link/log_train_pixel_link_512_512.log\n",
            "INFO:tensorflow:loading config.py from /content/pixel_link/config.py\n",
            "2021-07-09 09:24:40\n",
            "\n",
            "# =========================================================================== #\n",
            "# Training flags:\n",
            "# =========================================================================== #\n",
            "{'batch_size': <absl.flags._flag.Flag object at 0x7f59b623be10>,\n",
            " 'checkpoint_exclude_scopes': <absl.flags._flag.Flag object at 0x7f59b6248210>,\n",
            " 'checkpoint_path': <absl.flags._flag.Flag object at 0x7f59b8a5e810>,\n",
            " 'dataset_dir': <absl.flags._flag.Flag object at 0x7f59b6248850>,\n",
            " 'dataset_name': <absl.flags._flag.Flag object at 0x7f59b6248710>,\n",
            " 'dataset_split_name': <absl.flags._flag.Flag object at 0x7f59b6248790>,\n",
            " 'gpu_memory_fraction': <absl.flags._flag.Flag object at 0x7f59b623bd10>,\n",
            " 'h': <tensorflow.python.platform.app._HelpFlag object at 0x7f59b62489d0>,\n",
            " 'help': <tensorflow.python.platform.app._HelpFlag object at 0x7f59b62489d0>,\n",
            " 'helpfull': <tensorflow.python.platform.app._HelpfullFlag object at 0x7f59b6248a50>,\n",
            " 'helpshort': <tensorflow.python.platform.app._HelpshortFlag object at 0x7f59b6248ad0>,\n",
            " 'ignore_missing_vars': <absl.flags._flag.BooleanFlag object at 0x7f59b88e7490>,\n",
            " 'learning_rate': <absl.flags._flag.Flag object at 0x7f59b623bed0>,\n",
            " 'log_every_n_steps': <absl.flags._flag.Flag object at 0x7f59b62480d0>,\n",
            " 'max_number_of_steps': <absl.flags._flag.Flag object at 0x7f59b623bfd0>,\n",
            " 'momentum': <absl.flags._flag.Flag object at 0x7f59b62482d0>,\n",
            " 'moving_average_decay': <absl.flags._flag.Flag object at 0x7f59b62484d0>,\n",
            " 'num_gpus': <absl.flags._flag.Flag object at 0x7f59b623be90>,\n",
            " 'num_preprocessing_threads': <absl.flags._flag.Flag object at 0x7f59b6248650>,\n",
            " 'num_readers': <absl.flags._flag.Flag object at 0x7f59b6248590>,\n",
            " 'train_dir': <absl.flags._flag.Flag object at 0x7f59d4e2abd0>,\n",
            " 'train_image_height': <absl.flags._flag.Flag object at 0x7f59b6248990>,\n",
            " 'train_image_width': <absl.flags._flag.Flag object at 0x7f59b62488d0>,\n",
            " 'using_moving_average': <absl.flags._flag.BooleanFlag object at 0x7f59b62483d0>,\n",
            " 'weight_decay': <absl.flags._flag.Flag object at 0x7f59b6248390>}\n",
            "\n",
            "# =========================================================================== #\n",
            "# pixel_link net parameters:\n",
            "# =========================================================================== #\n",
            "'__name__=config'\n",
            "'__package__='\n",
            "'__file__=/content/pixel_link/config.py'\n",
            "'__cached__=/content/pixel_link/__pycache__/config.cpython-37.pyc'\n",
            "'r_mean=123.0'\n",
            "'g_mean=117.0'\n",
            "'b_mean=104.0'\n",
            "'rgb_mean=[123.0, 117.0, 104.0]'\n",
            "'use_rotation=True'\n",
            "'rotation_prob=0.5'\n",
            "'max_expand_scale=1'\n",
            "'expand_prob=0'\n",
            "'min_object_covered=0.1'\n",
            "'bbox_crop_overlap=0.2'\n",
            "'crop_aspect_ratio_range=(0.5, 2.0)'\n",
            "'area_range=[0.1, 1]'\n",
            "'flip=False'\n",
            "'using_shorter_side_filtering=True'\n",
            "'min_shorter_side=10'\n",
            "'max_shorter_side=inf'\n",
            "'decode_method=DECODE_METHOD_join'\n",
            "'min_area=300'\n",
            "'min_height=10'\n",
            "'dropout_ratio=0'\n",
            "'max_neg_pos_ratio=3'\n",
            "'feat_fuse_type=cascade_conv1x1_upsample_sum'\n",
            "'pixel_neighbour_type=PIXEL_NEIGHBOUR_TYPE_8'\n",
            "'model_type=vgg16'\n",
            "\"feat_layers=['conv3_3', 'conv4_3', 'conv5_3', 'fc7']\"\n",
            "'strides=[4]'\n",
            "'pixel_cls_weight_method=PIXEL_CLS_WEIGHT_bbox_balanced'\n",
            "'bbox_border_width=1'\n",
            "'pixel_cls_border_weight_lambda=1.0'\n",
            "'pixel_cls_loss_weight_lambda=2.0'\n",
            "'pixel_link_neg_loss_weight_lambda=1.0'\n",
            "'pixel_link_loss_weight=1.0'\n",
            "'num_classes=2'\n",
            "'ignore_label=-1'\n",
            "'background_label=0'\n",
            "'text_label=1'\n",
            "'data_format=NHWC'\n",
            "'train_with_ignored=False'\n",
            "'pixel_conf_threshold=0.6'\n",
            "'link_conf_threshold=0.9'\n",
            "'weight_decay=0.0001'\n",
            "'train_image_shape=[512, 512]'\n",
            "'score_map_shape=(128.0, 128.0)'\n",
            "'image_shape=[512, 512]'\n",
            "\"gpus=['/gpu:0']\"\n",
            "'num_clones=1'\n",
            "\"clone_scopes=['clone_0']\"\n",
            "'batch_size=16'\n",
            "'batch_size_per_gpu=16.0'\n",
            "'num_neighbours=8'\n",
            "\n",
            "# =========================================================================== #\n",
            "# Training | Evaluation dataset files:\n",
            "# =========================================================================== #\n",
            "['/content/drive/MyDrive/icdar2015/icdar2015_train.tfrecord']\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/slim/python/slim/data/parallel_reader.py:242: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/slim/python/slim/data/parallel_reader.py:94: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/pixel_link_py3/preprocessing/tf_image.py:329: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n",
            "WARNING:tensorflow:From /content/pixel_link_py3/preprocessing/ssd_vgg_preprocessing.py:246: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From train_pixel_link.py:153: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "<tensorflow.python.ops.data_flow_ops.FIFOQueue object at 0x7f59b52ba290>\n",
            "WARNING:tensorflow:From train_pixel_link.py:187: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "INFO:tensorflow:using moving average in training,         with decay = 0.999900\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2021-07-09 09:24:45.956612: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-07-09 09:24:45.961874: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-07-09 09:24:45.962085: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5558c1f5bc80 executing computations on platform Host. Devices:\n",
            "2021-07-09 09:24:45.962125: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path /content/pixel_link/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, /content/drive/MyDrive/icdar2015/icdar2015_train.tfrecord; No such file or directory\n",
            "\t [[{{node icdar2015_data_provider/parallel_read/ReaderReadV2}}]]\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "2021-07-09 09:24:52.202779: W tensorflow/core/kernels/queue_base.cc:285] _3_icdar2015_prefetch_queue/prefetch_queue/fifo_queue: Skipping cancelled dequeue attempt with queue not closed\n",
            "INFO:tensorflow:Caught OutOfRangeError. Stopping Training. FIFOQueue '_3_icdar2015_prefetch_queue/prefetch_queue/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n",
            "\t [[node clone_0/fifo_queue_Dequeue (defined at train_pixel_link.py:203) ]]\n",
            "\n",
            "Caused by op 'clone_0/fifo_queue_Dequeue', defined at:\n",
            "  File \"train_pixel_link.py\", line 296, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"train_pixel_link.py\", line 291, in main\n",
            "    train_op = create_clones(batch_queue)\n",
            "  File \"train_pixel_link.py\", line 203, in create_clones\n",
            "    b_pixel_link_label, b_pixel_link_weight = batch_queue.dequeue()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 445, in dequeue\n",
            "    self._queue_ref, self._dtypes, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3908, in queue_dequeue_v2\n",
            "    timeout_ms=timeout_ms, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "OutOfRangeError (see above for traceback): FIFOQueue '_3_icdar2015_prefetch_queue/prefetch_queue/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n",
            "\t [[node clone_0/fifo_queue_Dequeue (defined at train_pixel_link.py:203) ]]\n",
            "\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n",
            "Traceback (most recent call last):\n",
            "  File \"train_pixel_link.py\", line 296, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"train_pixel_link.py\", line 292, in main\n",
            "    train(train_op)\n",
            "  File \"train_pixel_link.py\", line 280, in train\n",
            "    session_config = sess_config\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 785, in train\n",
            "    ignore_live_threads=ignore_live_threads)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/supervisor.py\", line 832, in stop\n",
            "    ignore_live_threads=ignore_live_threads)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\n",
            "    six.reraise(*self._exc_info_to_raise)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
            "    enqueue_callable()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
            "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/drive/MyDrive/icdar2015/icdar2015_train.tfrecord; No such file or directory\n",
            "\t [[{{node icdar2015_data_provider/parallel_read/ReaderReadV2}}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDcxd-c4sNQ3"
      },
      "source": [
        "# Convert dataset to TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H91ckxO1p5X4",
        "outputId": "b7798501-a095-49fe-f9bb-3e2043bf3bd7"
      },
      "source": [
        "! cd {PIXEL_LINK_ROOT}/datasets; python icdar2015_to_tfrecords.py "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "/content/pixel_link_py3/datasets/content/drive/MyDrive/icdar2015/ch4_training_localization_transcription_gt /content/pixel_link_py3/datasets/content/drive/MyDrive/icdar2015/ch4_training_images\n",
            "Traceback (most recent call last):\n",
            "  File \"icdar2015_to_tfrecords.py\", line 71, in <module>\n",
            "    'content/drive/MyDrive/ch4_training_localization_transcription_gt') # gt_path\n",
            "  File \"icdar2015_to_tfrecords.py\", line 10, in cvt_to_tfrecords\n",
            "    image_names = util.io.ls(data_path, '.jpg')#[0:10];\n",
            "  File \"/content/pixel_link_py3/pylib/src/util/io_.py\", line 97, in ls\n",
            "    files = os.listdir(path)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/pixel_link_py3/datasets/content/drive/MyDrive/ch4_training_images'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB3gYH3rvzRP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}